{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061d50cc",
   "metadata": {},
   "source": [
    "# Data gathering/Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfda2782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Datasets\n",
    "#download the dataset here, train.csv and test.csv https://www.kaggle.com/competitions/titanic/data\n",
    "import pandas as pd\n",
    "traindata=pd.read_csv(\"train.csv\")\n",
    "traindata.head()\n",
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce86b51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin          687\n",
       "Age            177\n",
       "Embarked         2\n",
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null data\n",
    "traindata.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d799631",
   "metadata": {},
   "source": [
    "# Preparation of Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d737aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing some parts to dataset \n",
    "def process(data):\n",
    "    #removing columns to minimize the parameters to check\n",
    "    cleandata = data.drop(columns=[\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n",
    "    \n",
    "    return(cleandata)\n",
    "\n",
    "traindata=process(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7162aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         177\n",
       "Embarked      2\n",
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e15385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling up the null data with mean value of the age\n",
    "col=[\"Age\"]\n",
    "\n",
    "for cell in col:\n",
    "    traindata[cell].fillna(traindata[cell].mean(),inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b065f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked    2\n",
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for changes in the null \n",
    "traindata.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c874e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing 2 null values in Embarked column\n",
    "traindata.Embarked.fillna(\"U\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de0f4116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4075e5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n",
      "['C' 'Q' 'S' 'U']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    1  22.0      1      0   7.2500         2\n",
       "1         1       1    0  38.0      1      0  71.2833         0\n",
       "2         1       3    0  26.0      0      0   7.9250         2\n",
       "3         1       1    0  35.0      1      0  53.1000         2\n",
       "4         0       3    1  35.0      0      0   8.0500         2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting male = 1, female = 0 , C=0 , Q= 1 , S= 2, U=3\n",
    "from sklearn import preprocessing\n",
    "le= preprocessing.LabelEncoder()\n",
    "\n",
    "cols=[\"Sex\",\"Embarked\"]\n",
    "\n",
    "for col in cols:\n",
    "    traindata[col]=le.fit_transform(traindata[col])\n",
    "    print(le.classes_)\n",
    "    \n",
    "traindata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52144be",
   "metadata": {},
   "source": [
    "#  Model Trial, Training, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "991d20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "y= traindata[\"Survived\"]\n",
    "x= traindata.drop(\"Survived\", axis=1)\n",
    "x_train,x_test , y_train, y_test = train_test_split (x,y,\n",
    "                                                     test_size= 0.2, #20% test size, 80% train size\n",
    "                                                     random_state=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbe43a",
   "metadata": {},
   "source": [
    "Support Vector Machine Model (default Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f1103e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 70.94972067039106\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "svmclf = svm.SVC() #no parameters, set to default\n",
    "\n",
    "#Train the model using the training sets\n",
    "svmclf.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "svm_pred = svmclf.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "# Model Accuracy Checking\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(y_test, svm_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4a7e1",
   "metadata": {},
   "source": [
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5292203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistics Regression Accuracy: 85.47486033519553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#logistic regression model with 200 iteration \n",
    "lrclf= LogisticRegression(max_iter=200).fit(x_train,y_train) \n",
    "lr_pred= lrclf.predict(x_test)\n",
    "\n",
    "print(\" Logistics Regression Accuracy:\",metrics.accuracy_score(y_test, lr_pred)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeebc36c",
   "metadata": {},
   "source": [
    "Sequential Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7b1fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64,activation = 'relu', input_dim=7))\n",
    "model.add(Dense(32,activation = 'relu' ))\n",
    "model.add(Dense(16,activation = 'relu' ))\n",
    "model.add(Dense(16,activation = 'relu' ))\n",
    "model.add(Dense(1,activation = 'sigmoid' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e74eb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the layers of the model with optimizer, loss, metrics \n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "818c1bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 7ms/step - loss: 0.7044 - accuracy: 0.6404\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.6643\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.6601\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6742\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.6699\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.6728\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.6756\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6050 - accuracy: 0.6826\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6018 - accuracy: 0.6840\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5988 - accuracy: 0.6826\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5955 - accuracy: 0.6980\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5924 - accuracy: 0.7022\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.7008\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5879 - accuracy: 0.6952\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5876 - accuracy: 0.6980\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5853 - accuracy: 0.6994\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5827 - accuracy: 0.6980\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5837 - accuracy: 0.6966\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.7022\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.6980\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5785 - accuracy: 0.7135\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7051\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5730 - accuracy: 0.7022\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5702 - accuracy: 0.7051\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5691 - accuracy: 0.7233\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5632 - accuracy: 0.7107\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5640 - accuracy: 0.7093\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5605 - accuracy: 0.7135\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.7121\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7135\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.7008\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.7079\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5584 - accuracy: 0.7205\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7191\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7219\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7247\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7135\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5381 - accuracy: 0.7163\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5261 - accuracy: 0.7317\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7331\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7374\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5173 - accuracy: 0.7416\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.7416\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7430\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7486\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.7388\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.7640\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7669\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7837\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7725\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7556\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4960 - accuracy: 0.7584\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7654\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7697\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4965 - accuracy: 0.7837\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7809\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7767\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7626\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7809\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7570\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7781\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7893\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.7725\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7907\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7879\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7697\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7837\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4646 - accuracy: 0.7893\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7809\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.7683\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7978\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7809\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.7949\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7767\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7907\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7893\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.7879\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7851\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7879\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7865\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4628 - accuracy: 0.7893\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7949\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7865\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7879\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7935\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.8034\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7851\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7865\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7809\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4547 - accuracy: 0.7992\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7935\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7865\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7921\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7949\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7879\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7865\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4452 - accuracy: 0.8062\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7893\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.8006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1fda09450>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fitting\n",
    "model.fit(x_train, y_train, epochs=100, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e36948f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 3ms/step - loss: 0.4420 - accuracy: 0.7865\n",
      "Accuracy: 78.65\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                512       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,409\n",
      "Trainable params: 3,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model evaluation \n",
    "_, accuracy=model.evaluate(x_train,y_train)\n",
    "\n",
    "print('Accuracy: %.2f' %(accuracy*100))\n",
    "seqaccu=accuracy*100\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b1fc5",
   "metadata": {},
   "source": [
    "Perception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d583a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.94972067039106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "perpred = perceptron.predict(x_test)\n",
    "peraccu=metrics.accuracy_score(y_test, perpred,)\n",
    "print(peraccu*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05b35a",
   "metadata": {},
   "source": [
    "# Hypertuning the best model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dfafe5",
   "metadata": {},
   "source": [
    "Super Vector Machine Parameters hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d83197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.613 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.613 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.615 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.613 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.699 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.685 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.662 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.662 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.671 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.662 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.662 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.608 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.664 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.683 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.683 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.718 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.685 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.669 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.622 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.613 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.641 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.685 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.685 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.711 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.697 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.690 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.711 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.704 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.741 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.690 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.718 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.643 total time=   0.2s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.636 total time=   0.1s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.620 total time=   0.1s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.655 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.613 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.713 total time=   0.1s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.685 total time=   0.1s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.704 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.641 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.741 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.676 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.754 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.746 total time=   0.2s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.853 total time=   0.2s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.797 total time=   0.1s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.704 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.761 total time=   0.1s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.775 total time=   0.1s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.650 total time=   0.1s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.629 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.634 total time=   0.1s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.641 total time=   0.0s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.627 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.685 total time=   0.2s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.678 total time=   0.2s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.711 total time=   0.1s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.662 total time=   0.2s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.704 total time=   0.1s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.734 total time=   0.4s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.685 total time=   0.2s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.641 total time=   0.3s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.718 total time=   0.4s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.704 total time=   0.6s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.860 total time=   0.4s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.683 total time=   0.2s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.746 total time=   0.2s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.810 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#setting parameters to test for fitting\n",
    "svmparam_grid = {'C':[0.1, 1, 10, 100, 1000],'gamma':[1,0.1,0.01,0.001],'kernel':['rbf']}\n",
    "gridsvm=GridSearchCV(svmclf,svmparam_grid, refit = True, verbose=3)\n",
    "gridsvm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "633ee6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "best estimators:  SVC(C=100, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "#display best performing parameters\n",
    "print(\"best parameters: \",gridsvm.best_params_)\n",
    "print(\"best estimators: \",gridsvm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9b685d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With tuned parameters SVM Accuracy: 87.70949720670392\n"
     ]
    }
   ],
   "source": [
    "tunedsvmclf = svm.SVC(C=100, gamma= 0.001, kernel='rbf') #with hypertuned parameters \n",
    "\n",
    "#Train the model using the training sets\n",
    "tunedsvmclf.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "tunedsvm_pred = tunedsvmclf.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "# Model Accuracy Checking with new parameters \n",
    "print(\"With tuned parameters SVM Accuracy:\",metrics.accuracy_score(y_test, tunedsvm_pred)*100)\n",
    "\n",
    "tunedsvmaccu=(metrics.accuracy_score(y_test, tunedsvm_pred) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab41b9",
   "metadata": {},
   "source": [
    "Logistic Regression Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd4087d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "240 fits failed out of a total of 1440.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "240 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.61657152        nan 0.61657152 0.66146627 0.65443984 0.6600598\n",
      " 0.61657152        nan 0.61657152 0.66146627 0.653057   0.65725868\n",
      " 0.61657152        nan 0.61657152 0.66146627 0.65164462 0.653057\n",
      " 0.61657152        nan 0.61657152 0.66146627 0.65024406 0.65445756\n",
      " 0.61657152        nan 0.61657152 0.65725277 0.65865924 0.65725277\n",
      " 0.61657152        nan 0.61657152 0.65725277 0.65586994 0.65585221\n",
      " 0.61657152        nan 0.61657152 0.65725277 0.6572705  0.65585221\n",
      " 0.61657152        nan 0.61657152 0.65725277 0.65867697 0.65585221\n",
      " 0.61938446        nan 0.61375858 0.66289638 0.661484   0.66147809\n",
      " 0.61938446        nan 0.62360387 0.66289638 0.66289638 0.66148991\n",
      " 0.61938446        nan 0.62360387 0.66289638 0.66289638 0.66148991\n",
      " 0.61938446        nan 0.62360387 0.66289638 0.66289638 0.66148991\n",
      " 0.6572705         nan 0.65586403 0.67834982 0.67413041 0.661484\n",
      " 0.6572705         nan 0.65588767 0.67834982 0.67694335 0.67694335\n",
      " 0.6572705         nan 0.64606011 0.67834982 0.67694335 0.67694335\n",
      " 0.6572705         nan 0.65027952 0.67834982 0.67694335 0.67694335\n",
      " 0.65586403        nan 0.65586403 0.68537626 0.67413041 0.66851044\n",
      " 0.65586403        nan 0.65586403 0.68537626 0.68537626 0.68256332\n",
      " 0.65586403        nan 0.65586403 0.68537626 0.68537626 0.68537626\n",
      " 0.65586403        nan 0.65586403 0.68537626 0.68537626 0.68537626\n",
      " 0.65725277        nan 0.65725277 0.70783841 0.67694335 0.66851044\n",
      " 0.65725277        nan 0.65725277 0.70783841 0.70221844 0.68958976\n",
      " 0.65725277        nan 0.65305109 0.70783841 0.70643194 0.70502547\n",
      " 0.65725277        nan 0.65585221 0.70783841 0.70643194 0.70502547\n",
      " 0.71767188        nan 0.65585221 0.73173067 0.67834982 0.66851044\n",
      " 0.71767188        nan 0.66990509 0.73173067 0.70783841 0.68958976\n",
      " 0.71767188        nan 0.69096668 0.73173067 0.7218972  0.71626541\n",
      " 0.71767188        nan 0.69659256 0.73173067 0.72470423 0.71627132\n",
      " 0.76256663        nan 0.66007753 0.76964035 0.67834982 0.66851044\n",
      " 0.76256663        nan 0.6909785  0.76964035 0.71345838 0.69661029\n",
      " 0.76256663        nan 0.70923306 0.76964035 0.73734473 0.71346429\n",
      " 0.76256663        nan 0.72891182 0.76964035 0.74856694 0.73734473\n",
      " 0.77800234        nan 0.66570341 0.77522486 0.67834982 0.66851044\n",
      " 0.77800234        nan 0.69520973 0.77522486 0.71486485 0.69801676\n",
      " 0.77800234        nan 0.71485894 0.77522486 0.73872756 0.71346429\n",
      " 0.77800234        nan 0.74153459 0.77522486 0.76401447 0.73872756\n",
      " 0.78502878        nan 0.66851044 0.78362822 0.67834982 0.66851044\n",
      " 0.78502878        nan 0.69801676 0.78362822 0.71486485 0.69801676\n",
      " 0.78502878        nan 0.71205782 0.78362822 0.73872756 0.71487076\n",
      " 0.78502878        nan 0.73592053 0.78362822 0.76541503 0.73872756\n",
      " 0.78222766        nan 0.66851044 0.78362231 0.67834982 0.66851044\n",
      " 0.78222766        nan 0.69801676 0.78362231 0.71205782 0.69801676\n",
      " 0.78222766        nan 0.71346429 0.78362231 0.74716047 0.71346429\n",
      " 0.78222766        nan 0.74575991 0.78362231 0.77102318 0.74716047\n",
      " 0.78082119        nan 0.66851044 0.78222766 0.67834982 0.66851044\n",
      " 0.78082119        nan 0.69801676 0.78222766 0.71205782 0.69801676\n",
      " 0.78082119        nan 0.71346429 0.78222766 0.74856694 0.71346429\n",
      " 0.78082119        nan 0.74856694 0.78222766 0.77523077 0.74856694\n",
      " 0.77941472        nan 0.66851044 0.78222766 0.67834982 0.66851044\n",
      " 0.77941472        nan 0.69801676 0.78222766 0.71205782 0.69801676\n",
      " 0.77941472        nan 0.71346429 0.78222766 0.74856694 0.71346429\n",
      " 0.77941472        nan 0.7499675  0.78222766 0.77523077 0.74856694\n",
      " 0.77941472        nan 0.66851044 0.78082119 0.67834982 0.66851044\n",
      " 0.77941472        nan 0.69801676 0.78082119 0.71205782 0.69801676\n",
      " 0.77941472        nan 0.71346429 0.78082119 0.74856694 0.71346429\n",
      " 0.77941472        nan 0.74856694 0.78082119 0.77523077 0.74856694\n",
      " 0.77941472        nan 0.66851044 0.77941472 0.67834982 0.66851044\n",
      " 0.77941472        nan 0.69801676 0.77941472 0.71205782 0.69801676\n",
      " 0.77941472        nan 0.71346429 0.77941472 0.74856694 0.71346429\n",
      " 0.77941472        nan 0.74856694 0.77941472 0.77523077 0.74856694\n",
      " 0.77941472        nan 0.66851044 0.77941472 0.67834982 0.66851044\n",
      " 0.77941472        nan 0.69801676 0.77941472 0.71205782 0.69801676\n",
      " 0.77941472        nan 0.71346429 0.77941472 0.74856694 0.71346429\n",
      " 0.77941472        nan 0.74856694 0.77941472 0.77523077 0.74856694\n",
      " 0.77941472        nan 0.66851044 0.77941472 0.67834982 0.66851044\n",
      " 0.77941472        nan 0.69801676 0.77941472 0.71205782 0.69801676\n",
      " 0.77941472        nan 0.71346429 0.77941472 0.74856694 0.71346429\n",
      " 0.77941472        nan 0.74856694 0.77941472 0.77523077 0.74856694\n",
      " 0.77941472        nan 0.66851044 0.77941472 0.67834982 0.66851044\n",
      " 0.77941472        nan 0.69801676 0.77941472 0.71205782 0.69801676\n",
      " 0.77941472        nan 0.71346429 0.77941472 0.74856694 0.71346429\n",
      " 0.77941472        nan 0.74856694 0.77941472 0.77523077 0.74856694\n",
      " 0.77941472        nan 0.66851044 0.77941472 0.67834982 0.66851044\n",
      " 0.77941472        nan 0.69801676 0.77941472 0.71205782 0.69801676\n",
      " 0.77941472        nan 0.71346429 0.77941472 0.74856694 0.71346429\n",
      " 0.77941472        nan 0.74856694 0.77941472 0.77523077 0.74856694\n",
      " 0.77941472        nan 0.66851044 0.77941472 0.67834982 0.66851044\n",
      " 0.77941472        nan 0.69801676 0.77941472 0.71205782 0.69801676\n",
      " 0.77941472        nan 0.71346429 0.77941472 0.74856694 0.71346429\n",
      " 0.77941472        nan 0.74856694 0.77941472 0.77523077 0.74856694]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                          &#x27;max_iter&#x27;: [100, 1000, 2500, 5000],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]}],\n",
       "             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                          &#x27;max_iter&#x27;: [100, 1000, 2500, 5000],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                          &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]}],\n",
       "             verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid=[{'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                          'max_iter': [100, 1000, 2500, 5000],\n",
       "                          'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear', 'sag', 'saga']}],\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyper tuning for logistic regression\n",
    "import numpy as np\n",
    "lrparam_grid = [ \n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "     'C' :np.logspace(-4, 4, 20),\n",
    "     'solver' : ['liblinear','sag','saga'],\n",
    "     'max_iter' : [100, 1000,2500, 5000]\n",
    "    }\n",
    "]\n",
    "gridlr = GridSearchCV(LogisticRegression(), param_grid = lrparam_grid, cv = 3, verbose=True, n_jobs=-1)\n",
    "gridlr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e09ba66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.615848211066026, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "best estimators:  LogisticRegression(C=0.615848211066026, penalty='l1', solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "#displaying best parameters\n",
    "print(\"best parameters: \",gridlr.best_params_)\n",
    "print(\"best estimators: \",gridlr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5b576a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logistics Regression Accuracy: 86.03351955307262\n"
     ]
    }
   ],
   "source": [
    "#logistic regression model with best parameters in hypertuning\n",
    "tunedlrclf= LogisticRegression(C= 0.615848211066026, max_iter= 100,penalty= 'l1', solver= 'liblinear').fit(x_train,y_train)\n",
    "\n",
    "#using the model with new parameters for prediction\n",
    "tunedlr_pred= tunedlrclf.predict(x_test)\n",
    "\n",
    "# Model Accuracy Checking with new parameters \n",
    "print(\" Logistics Regression Accuracy:\",metrics.accuracy_score(y_test, tunedlr_pred)*100) \n",
    "\n",
    "tunedlraccu=metrics.accuracy_score(y_test, tunedlr_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476492d6",
   "metadata": {},
   "source": [
    "# Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8fa5f",
   "metadata": {},
   "source": [
    "ranking the four model with tuned parameters(except sequential and perception) used we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb75d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine:  87.70949720670392\n",
      "   Logistic Regression:  86.03351955307262\n",
      "      sequential Model:  78.65168452262878\n",
      "      Perception Model:  70.94972067039106\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine: \",tunedsvmaccu)\n",
    "print(\"   Logistic Regression: \",tunedlraccu)\n",
    "print(\"      sequential Model: \",seqaccu)\n",
    "print(\"      Perception Model: \",peraccu*100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa2d9cb",
   "metadata": {},
   "source": [
    "# Testing the Models using test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92d2fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       892\n",
      "1       893\n",
      "2       894\n",
      "3       895\n",
      "4       896\n",
      "       ... \n",
      "413    1305\n",
      "414    1306\n",
      "415    1307\n",
      "416    1308\n",
      "417    1309\n",
      "Name: PassengerId, Length: 418, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing test data \n",
    "testdata=pd.read_csv(\"test.csv\")\n",
    "yid=testdata[\"PassengerId\"]  #storing passenger id to a variable for later use\n",
    "print(yid)\n",
    "testdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97b95847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         86\n",
       "Fare         1\n",
       "Pclass       0\n",
       "Sex          0\n",
       "SibSp        0\n",
       "Parch        0\n",
       "Embarked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the other columns based on our preprocessing in the training data\n",
    "testdata=process(testdata)\n",
    "testdata.head()\n",
    "testdata.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dace225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n",
      "['C' 'Q' 'S']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filling null values the average of the data where it belongs\n",
    "col=[\"Age\",\"Fare\"]\n",
    "for cell in col:\n",
    "    testdata[cell].fillna(testdata[cell].mean(),inplace=True)\n",
    "\n",
    "#converting text to numeric value same on the last preprocessing\n",
    "cols=[\"Sex\",\"Embarked\"]\n",
    "\n",
    "for col in cols:\n",
    "    testdata[col]=le.fit_transform(testdata[col])\n",
    "    print(le.classes_)\n",
    "    \n",
    "traindata.head()    \n",
    "    \n",
    "testdata.isnull().sum().sort_values(ascending=False) #Checking null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f647c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#prediction of the three models used\n",
    "svmprediction = tunedsvmclf.predict(testdata)\n",
    "lrprediction  = tunedlrclf.predict(testdata)\n",
    "seqprediction =  model.predict(testdata)\n",
    "perprediction = perceptron.predict(testdata)\n",
    "\n",
    "#rounding off the values of the sequential model prediction\n",
    "seqprediction = np.array(seqprediction)\n",
    "seqprediction = seqprediction.flatten()\n",
    "seqprediction[seqprediction<0.5] = 0\n",
    "seqprediction[seqprediction>0] = 1\n",
    "seqprediction = seqprediction.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a75ba",
   "metadata": {},
   "source": [
    "# Saving prediction of the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c49dca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving svm model prediction\n",
    "df= pd.DataFrame({\"PassengerId\":yid.values,\n",
    "                \"Survived\":svmprediction})\n",
    "\n",
    "df.to_csv(\"latestsvmsubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5127c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving logistic regression prediction\n",
    "df= pd.DataFrame({\"PassengerId\":yid.values,\n",
    "                \"Survived\":lrprediction})\n",
    "\n",
    "df.to_csv(\"latestlrsubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c4b3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving sequential model prediction\n",
    "df= pd.DataFrame({\"PassengerId\":yid.values,\n",
    "                \"Survived\":seqprediction})\n",
    "\n",
    "df.to_csv(\"latestseqsubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "696f9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving sequential model prediction\n",
    "df= pd.DataFrame({\"PassengerId\":yid.values,\n",
    "                \"Survived\":perprediction})\n",
    "\n",
    "df.to_csv(\"latestpersubmission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0493d",
   "metadata": {},
   "source": [
    "# Comparisons,Analysis, Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7f36e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Kaggle Score:</th>\n",
       "      <th>hypertuned?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>87.709497</td>\n",
       "      <td>0.73205</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>86.033520</td>\n",
       "      <td>0.76555</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sequential</td>\n",
       "      <td>78.651685</td>\n",
       "      <td>0.74401</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>70.949721</td>\n",
       "      <td>0.65550</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      Score  Kaggle Score: hypertuned?\n",
       "0                  SVM  87.709497        0.73205         Yes\n",
       "1  Logistic Regression  86.033520        0.76555         Yes\n",
       "2           Sequential  78.651685        0.74401          No\n",
       "3           Perceptron  70.949721        0.65550          No"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating table\n",
    "models = pd.DataFrame({'Model':[\"SVM\",\"Perceptron\",\"Sequential\",\"Logistic Regression\"],\n",
    "                       'Score': [tunedsvmaccu,peraccu*100,seqaccu,tunedlraccu],\n",
    "                        'Kaggle Score:':[0.73205,0.65550,0.74401,0.76555],\n",
    "                      \"hypertuned?\": [\"Yes\",\"No\",\"No\",\"Yes\"]}\n",
    "                     )\n",
    "                    \n",
    "models.sort_values(by = 'Score', ascending = False, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f444a5",
   "metadata": {},
   "source": [
    " Model Analysis and Comparisons\n",
    " \n",
    " As we can see in the summary of the result, the best accuracy goes to the Support Vector Machine, followed by logistic regression, sequential, and Perception model.\n",
    " \n",
    " Eventhough we know that the accuracy of the SVM shows a higher percentage, the most realible model here is the logistic regression. As I try to used the results of my prediction to check it in the Kaggle competition, Logistic Regression Model got the highest accuracy rate. \n",
    "\n",
    "\n",
    "Another observation is that the hypertuned model performs better since different parameters were tried just to find the highest accuracy possible.\n",
    "\n",
    "Conclusions\n",
    "\n",
    "Between machine learning(SVM,Logistic Regression) and nueral networks(sequential, Perceptron), I observed that Machine Learning models performs well compared to nueral networks in this type of problem. I actually think that the reason why the nueral networks have poor performance is because I lack familiarity to the models and how to use them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.S: I really love the programming exam and trying to engineered data into much readable values for the machine to analyzed. This exam surely made me realize the surface of the data science field and I am thrilled to learn as much as I can.\n",
    "\n",
    "P.P.S: I'll try to create and customized this data even after the exam ends. I'll try to be on the Top 1% of the kaggle competition hehehehehe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6471b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stephen Felix \n",
    "#love the exam but not fun because of the time constraints sana all full term\n",
    "#Kaggle Novice \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ba37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
